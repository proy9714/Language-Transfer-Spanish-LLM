{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SourceDocumentLoader:\n",
    "    \n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        self.pages = None\n",
    "        \n",
    "    # Load the pdf\n",
    "    def load_pdf(self):\n",
    "        loader = PyPDFLoader(self.filepath)\n",
    "        self.pages = loader.load_and_split()\n",
    "        \n",
    "        print(f\"Loaded {len(self.pages)} pages!\")\n",
    "        \n",
    "        self.modify_sources()\n",
    "        \n",
    "    # Modify the track sources\n",
    "    def modify_sources(self):\n",
    "        track_number = 0\n",
    "        for index, page in enumerate(self.pages[7:]):\n",
    "            if page.page_content.startswith(\"Track\"):\n",
    "                track_number += 1\n",
    "                \n",
    "            page.metadata[\"source\"] = f\"Track {track_number}\"\n",
    "            \n",
    "    def get_pages(self):\n",
    "        return self.pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSplitter:\n",
    "    \n",
    "    def __init__(self, documents):\n",
    "        self.documents = documents\n",
    "        self.splitter = self.get_splitter()\n",
    "        \n",
    "    def get_splitter(self):\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200,\n",
    "        )\n",
    "        \n",
    "        return text_splitter \n",
    "    \n",
    "    def _get_splits(self):\n",
    "        return self.splitter.split_documents(self.documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStore:\n",
    "    \n",
    "    def __init__(self, documents, vectorstore_path, embeddings):\n",
    "        self.vector_store = FAISS\n",
    "        self.db = None\n",
    "        self.documents = documents\n",
    "        self.vector_store_path = vectorstore_path\n",
    "        self.embeddings = embeddings\n",
    "        \n",
    "        # Create the directory if it doesn't exist\n",
    "        os.makedirs(self.vector_store_path, exist_ok=True)\n",
    "    \n",
    "    def get_indices(self):\n",
    "        # First try to load the vector store from the vectorstore path else create and save it in that path\n",
    "        if os.path.exists(self.vector_store_path):\n",
    "            print(\"Loading vectorstore from folder!\")\n",
    "            self.db = FAISS.load_local(self.vector_store_path, self.embeddings)\n",
    "        \n",
    "        else:\n",
    "            print(\"Creating new vectorstore!\")\n",
    "            self.db = FAISS.from_documents(self.documents, self.embeddings)\n",
    "            self.db.save_local(self.vector_store_path)\n",
    "        \n",
    "        return self.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs, separator=\"\\n\\n\"):\n",
    "    return separator.join([d.page_content for d in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpanishMaster:\n",
    "    \n",
    "    def __init__(self, embeddings = OpenAIEmbeddings(), filepath: str = \"assets/Complete+Spanish+transcript+-+2019+final.pdf\", vectorstore_path:str = \"assets/vectorstore\", llm = ChatOpenAI(temperature=0)):\n",
    "        self.filepath = filepath\n",
    "        self.vectorstore_path = vectorstore_path\n",
    "        self.pages = None\n",
    "        self.splits = None\n",
    "        self.db = None\n",
    "        self.retriever = None\n",
    "        self.chain = None\n",
    "        self.llm = llm\n",
    "        self.embeddings = embeddings\n",
    "        \n",
    "        self._setup_spanish_master()\n",
    "        self._define_response_chain()\n",
    "    \n",
    "    def _load_document(self):\n",
    "        # Loading Document\n",
    "        document_loader = SourceDocumentLoader(self.filepath)\n",
    "        document_loader.load_pdf()\n",
    "        self.pages = document_loader.get_pages()\n",
    "        \n",
    "        print(\"Number of pages : \", len(self.pages))\n",
    "\n",
    "    def _get_splits(self):\n",
    "        # Splitting the document\n",
    "        splitter = TextSplitter(self.pages)\n",
    "        self.splits = splitter._get_splits()\n",
    "\n",
    "        print(\"Number of splits : \", len(self.splits))    \n",
    "    \n",
    "    def _get_vectorstore(self):\n",
    "        # Creating vector Store\n",
    "        vector_store = VectorStore(self.splits, self.vectorstore_path, self.embeddings)\n",
    "        self.db = vector_store.get_indices()\n",
    "\n",
    "    def _get_retriever(self):\n",
    "        # self.retriever = self.db.as_retriever()\n",
    "        \n",
    "        self.retriever = MultiQueryRetriever.from_llm(\n",
    "           retriever=self.db.as_retriever(), llm=self.llm\n",
    "        )\n",
    "    \n",
    "    def _get_prompt(self):\n",
    "        template = \"\"\"\n",
    "            Answer the Spanish language related question/questions in details, based ONLY on the following context:\n",
    "\n",
    "            {context}\n",
    "\n",
    "            The above context is from a \"Language Transfer\" course for learning Spanish. It is basically a sequence of interactions between a teacher and a student.\n",
    "            Always supplement your answers with the source track/tracks number/numbers where the user can refer for more details if possible.\n",
    "\n",
    "            Question: {question}\n",
    "        \"\"\"\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        \n",
    "        return prompt\n",
    "        \n",
    "    def _define_response_chain(self):\n",
    "        \n",
    "        prompt = self._get_prompt()\n",
    "        model = self.llm\n",
    "\n",
    "        self.chain = (\n",
    "            {\"context\": self.retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | prompt\n",
    "            | model\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "        \n",
    "    def _setup_spanish_master(self):\n",
    "        self._load_document()\n",
    "        self._get_splits()\n",
    "        self._get_vectorstore()\n",
    "        self._get_retriever()\n",
    "        \n",
    "    def get_response(self, question):\n",
    "        for chunk in self.chain.stream(question):\n",
    "            print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_master = SpanishMaster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=''content='In'content=' Spanish'content=','content=' there'content=' are'content=' specific'content=' rules'content=' for'content=' writing'content=' that'content=' can'content=' help'content=' learners'content=' understand'content=' pronunciation'content=' and'content=' stress'content=' in'content=' words'content='.'content=' One'content=' important'content=' rule'content=' is'content=' that'content=' if'content=' a'content=' word'content=' ends'content=' in'content=' a'content=' vowel'content=','content=' an'content=' n'content=','content=' or'content=' an'content=' s'content=','content=' the'content=' accent'content=' should'content=' be'content=' on'content=' the'content=' pen'content='ultimate'content=' syll'content='able'content=' ('content='second'content=' last'content=' syll'content='able'content=').'content=' For'content=' example'content=','content=' the'content=' word'content=' \"'content='con'content='cent'content='r'content='aci√≥n'content='\"'content=' follows'content=' this'content=' rule'content=','content=' where'content=' the'content=' stress'content=' is'content=' on'content=' the'content=' second'content=' last'content=' syll'content='able'content=' due'content=' to'content=' the'content=' word'content=' ending'content=' in'content=' a'content=' vowel'content=' followed'content=' by'content=' an'content=' n'content='.\\n\\n'content='Another'content=' rule'content=' is'content=' related'content=' to'content=' the'content=' use'content=' of'content=' accents'content=' in'content=' Spanish'content='.'content=' Acc'content='ents'content=' are'content=' used'content=' to'content=' indicate'content=' stress'content=' in'content=' words'content=','content=' but'content=' they'content=' are'content=' not'content=' used'content=' to'content=' change'content=' the'content=' sound'content=' of'content=' vowels'content=' like'content=' in'content=' French'content='.'content=' The'content=' general'content=' rule'content=' is'content=' that'content=' if'content=' a'content=' word'content=' ends'content=' in'content=' a'content=' vowel'content=','content=' an'content=' n'content=','content=' or'content=' an'content=' s'content=','content=' the'content=' accent'content=' should'content=' be'content=' on'content=' the'content=' pen'content='ultimate'content=' syll'content='able'content='.'content=' For'content=' example'content=','content=' the'content=' word'content=' \"'content='normal'content='\"'content=' in'content=' English'content=' becomes'content=' \"'content='normal'content='\"'content=' in'content=' Spanish'content=','content=' with'content=' the'content=' stress'content=' on'content=' the'content=' last'content=' syll'content='able'content=' due'content=' to'content=' the'content=' word'content=' ending'content=' in'content=' an'content=' l'content='.\\n\\n'content='Additionally'content=','content=' there'content=' is'content=' a'content=' rule'content=' regarding'content=' the'content=' pronunciation'content=' of'content=' certain'content=' sounds'content=' in'content=' Spanish'content='.'content=' For'content=' example'content=','content=' if'content=' a'content=' word'content=' has'content=' a'content=' /'content='j'content='/'content=' sound'content=' in'content=' English'content=','content=' it'content=' will'content=' become'content=' a'content=' /'content='kh'content='/'content=' sound'content=' in'content=' Spanish'content='.'content=' An'content=' example'content=' of'content=' this'content=' is'content=' the'content=' word'content=' \"'content='global'content=',\"'content=' which'content=' is'content=' pronounced'content=' as'content=' \"'content='global'content='\"'content=' in'content=' Spanish'content='.\\n\\n'content='(Source'content=':'content=' Track'content=' 'content='67'content=','content=' Track'content=' 'content='2'content=')'content=''"
     ]
    }
   ],
   "source": [
    "question = \"Tell me the writing rules for spanish, with examples for each\"\n",
    "spanish_master.get_response(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
