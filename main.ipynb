{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SourceDocumentLoader:\n",
    "    \n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        self.pages = None\n",
    "        \n",
    "    # Load the pdf\n",
    "    def load_pdf(self):\n",
    "        loader = PyPDFLoader(self.filepath)\n",
    "        self.pages = loader.load_and_split()\n",
    "        \n",
    "        print(f\"Loaded {len(self.pages)} pages!\")\n",
    "        \n",
    "        self.modify_sources()\n",
    "        \n",
    "    # Modify the track sources\n",
    "    def modify_sources(self):\n",
    "        track_number = 0\n",
    "        for index, page in enumerate(self.pages[7:]):\n",
    "            if page.page_content.startswith(\"Track\"):\n",
    "                track_number += 1\n",
    "                \n",
    "            page.metadata[\"source\"] = f\"Track {track_number}\"\n",
    "            \n",
    "    def get_pages(self):\n",
    "        return self.pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSplitter:\n",
    "    \n",
    "    def __init__(self, documents):\n",
    "        self.documents = documents\n",
    "        self.splitter = self.get_splitter()\n",
    "        \n",
    "    def get_splitter(self):\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200,\n",
    "        )\n",
    "        \n",
    "        return text_splitter \n",
    "    \n",
    "    def _get_splits(self):\n",
    "        return self.splitter.split_documents(self.documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStore:\n",
    "    \n",
    "    def __init__(self, documents, vectorstore_path, embeddings):\n",
    "        self.vector_store = FAISS\n",
    "        self.db = None\n",
    "        self.documents = documents\n",
    "        self.vector_store_path = vectorstore_path\n",
    "        self.embeddings = embeddings\n",
    "        \n",
    "        # Create the directory if it doesn't exist\n",
    "        os.makedirs(self.vector_store_path, exist_ok=True)\n",
    "    \n",
    "    def get_indices(self):\n",
    "        # First try to load the vector store from the vectorstore path else create and save it in that path\n",
    "        if os.path.exists(self.vector_store_path):\n",
    "            print(\"Loading vectorstore from folder!\")\n",
    "            self.db = FAISS.load_local(self.vector_store_path, self.embeddings)\n",
    "        \n",
    "        else:\n",
    "            print(\"Creating new vectorstore!\")\n",
    "            self.db = FAISS.from_documents(documents, self.embeddings)\n",
    "            self.db.save_local(self.vector_store_path)\n",
    "        \n",
    "        return self.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpanishMaster:\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            embeddings = OpenAIEmbeddings(),\n",
    "            filepath:str = \"assets/Complete+Spanish+transcript+-+2019+final.pdf\",\n",
    "            vectorstore_path:str = \"assets/vectorstore\",\n",
    "            llm = ChatOpenAI(temperature=0)\n",
    "        ):\n",
    "        self.filepath = filepath\n",
    "        self.vectorstore_path = vectorstore_path\n",
    "        self.pages = None\n",
    "        self.splits = None\n",
    "        self.db = None\n",
    "        self.retriever = None\n",
    "        self.chain = None\n",
    "        self.llm = llm\n",
    "        self.embeddings = embeddings\n",
    "        \n",
    "        self._define_response_chain()\n",
    "    \n",
    "    def _load_document(self):\n",
    "        # Loading Document\n",
    "        document_loader = SourceDocumentLoader(filepath=filepath)\n",
    "        document_loader.load_pdf()\n",
    "        self.pages = document_loader.get_pages()\n",
    "        \n",
    "        print(\"Number of pages : \", len(self.pages))\n",
    "\n",
    "    def _get_splits(self):\n",
    "        # Splitting the document\n",
    "        splitter = TextSplitter(documents=documents)\n",
    "        self.splits = splitter._get_splits()\n",
    "\n",
    "        print(\"Number of splits : \", len(self.splits))    \n",
    "    \n",
    "    def _get_vectorstore(self):\n",
    "        # Creating vector Store\n",
    "        vector_store = VectorStore(splits, self.vectorstore_path, self.embeddings)\n",
    "        self.db = vector_store.get_indices()\n",
    "\n",
    "    def _get_retriever(self):\n",
    "        # self.retriever = self.db.as_retriever()\n",
    "        \n",
    "        self.retriever = MultiQueryRetriever.from_llm(\n",
    "           retriever=self.db.as_retriever(), llm=self.llm\n",
    "        )\n",
    "    \n",
    "    def _get_prompt(self):\n",
    "        template = \"\"\"\n",
    "            Answer the Spanish language related question/questions in details, based ONLY on the following context:\n",
    "\n",
    "            {context}\n",
    "\n",
    "            The above context is from a \"Language Transfer\" course for learning Spanish. It is basically a sequence of interactions between a teacher and a student.\n",
    "            Always supplement your answers with the source track/tracks number/numbers where the user can refer for more details if possible.\n",
    "\n",
    "            Question: {question}\n",
    "        \"\"\"\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        \n",
    "        return prompt\n",
    "        \n",
    "    def _define_response_chain(self):\n",
    "        \n",
    "        prompt = self._get_prompt()\n",
    "        model = self.llm\n",
    "\n",
    "        self.chain = (\n",
    "            {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | prompt\n",
    "            | model\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "        \n",
    "    def setup_spanish_master(self):\n",
    "        self._load_document()\n",
    "        self._get_splits()\n",
    "        self._get_vectorstore()\n",
    "        self._get_retriever()\n",
    "        \n",
    "    def get_response(self, question):\n",
    "        for chunk in self.chain.stream(question):\n",
    "            print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs, separator=\"\\n\\n\"):\n",
    "    return separator.join([d.page_content for d in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_master = SpanishMaster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 511 pages!\n",
      "Number of pages :  511\n",
      "Number of splits :  1009\n",
      "Loading vectorstore from folder!\n"
     ]
    }
   ],
   "source": [
    "spanish_master.setup_spanish_master()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The writing rules for Spanish are as follows:\n",
      "1. If a word ends in a vowel, an n, or an s, the accent should be on the penultimate syllable (second last syllable). For example, \"hablamos\" and \"importante\" follow this rule.\n",
      "2. If a word ends in any other consonant that is not n or s, the natural accent place is at the end of the word. For example, \"comer\" and \"encontrar\" follow this rule.\n",
      "3. If a word breaks these rules, a written accent is used to show where the stress should be placed. For example, \"tradici√≥n\" breaks the rule and has a written accent on the last syllable.\n",
      "\n",
      "(Source: Track 67)"
     ]
    }
   ],
   "source": [
    "question = \"Tell me the writing rules for spanish, with examples for each\"\n",
    "spanish_master.get_response(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
